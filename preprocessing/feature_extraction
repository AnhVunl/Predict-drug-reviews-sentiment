# *Load packages*

import pandas as pd
import scipy.stats as stats
import pylab as pl
import nltk, re
import spacy
nlp = spacy.load('en_core_web_sm')

nltk.download('averaged_perceptron_tagger')
nltk.download('maxent_ne_chunker')
nltk.download('words')
import scipy
from scipy.sparse import csr_matrix, find, hstack

import numpy
import numpy as np
from nltk.corpus import stopwords
import pylab as pl
import matplotlib.pyplot as plt
%matplotlib inline
import os
os.listdir(os.getcwd())

from collections import defaultdict
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn import neighbors, datasets, preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
nltk.download('sentiwordnet')
from nltk.corpus import sentiwordnet as swn
from nltk import ngrams
from nltk.stem import WordNetLemmatizer

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
